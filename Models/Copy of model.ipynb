{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1k-oPiOYGyP7q4-imZUhJWP9tGPu-m5-B","timestamp":1677948081302}],"authorship_tag":"ABX9TyOBzdFuqGinM6ifscLjGhDJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["Importing"],"metadata":{"id":"ToEUTWrd2JO4"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"D0ErDNm0E68O","executionInfo":{"status":"ok","timestamp":1677936453122,"user_tz":-330,"elapsed":2819,"user":{"displayName":"NIRAJ MATERE","userId":"18266484789499151383"}}},"outputs":[],"source":["import pandas as pd\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import gensim\n","from gensim.summarization.summarizer import summarize\n","from sklearn.metrics import mean_squared_error\n","from math import sqrt"]},{"cell_type":"markdown","source":["Adding commentary data"],"metadata":{"id":"GR1ZASz3FcBV"}},{"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"id":"wKFw4KDKFE3V","executionInfo":{"status":"ok","timestamp":1677936554959,"user_tz":-330,"elapsed":101843,"user":{"displayName":"NIRAJ MATERE","userId":"18266484789499151383"}},"outputId":"569a8acb-9f13-4531-a4cc-ec5c2cae6f67"},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-8a81321b-e573-44cf-9690-df524770ec03\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-8a81321b-e573-44cf-9690-df524770ec03\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving IPL_Match_Highlights_Commentary.csv to IPL_Match_Highlights_Commentary (1).csv\n"]}]},{"cell_type":"code","source":["# Load the csv file\n","df = pd.read_csv(\"IPL_Match_Highlights_Commentary.csv\")"],"metadata":{"id":"7BOeyVgQFLUL","executionInfo":{"status":"ok","timestamp":1677936554959,"user_tz":-330,"elapsed":10,"user":{"displayName":"NIRAJ MATERE","userId":"18266484789499151383"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["Preprocessing of data."],"metadata":{"id":"wI3qf3fU-X4c"}},{"cell_type":"code","source":["nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lsORKRTEFpRY","executionInfo":{"status":"ok","timestamp":1677936554960,"user_tz":-330,"elapsed":9,"user":{"displayName":"NIRAJ MATERE","userId":"18266484789499151383"}},"outputId":"84447111-2aa9-4177-d1c0-3cc380e69626"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["nltk.download('omw-1.4')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YoBKQF3iGD-X","executionInfo":{"status":"ok","timestamp":1677936554961,"user_tz":-330,"elapsed":8,"user":{"displayName":"NIRAJ MATERE","userId":"18266484789499151383"}},"outputId":"76e84ce0-6ece-4598-f95f-ef50987f89da"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# Convert all text to lowercase\n","df[\"comment\"] = df[\"comment\"].astype(str).str.lower()\n","\n","# Remove punctuation\n","df[\"comment\"] = df[\"comment\"].astype(str).str.replace('[^\\w\\s]','')\n","\n","# Remove stop words\n","nltk.download('stopwords')\n","stop_words = set(stopwords.words('english'))\n","df[\"comment\"] = df[\"comment\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n","\n","# Tokenize words\n","df[\"comment\"] = df[\"comment\"].apply(lambda x: word_tokenize(x))\n","\n","# Lemmatize words\n","nltk.download('wordnet')\n","lemmatizer = WordNetLemmatizer()\n","df[\"comment\"] = df[\"comment\"].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n","\n","# Combine the tokenized words into a single string\n","df[\"comment\"] = df[\"comment\"].apply(lambda x: \" \".join(x))\n","\n","# Create a list of all the preprocessed comments\n","preprocessed_comments = df[\"comment\"].tolist()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bc9B3VCWFSnI","executionInfo":{"status":"ok","timestamp":1677936563607,"user_tz":-330,"elapsed":8652,"user":{"displayName":"NIRAJ MATERE","userId":"18266484789499151383"}},"outputId":"f5ac62eb-7ccd-4869-e0cd-2fd5a70004d2"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-6-07c81172199b>:5: FutureWarning: The default value of regex will change from True to False in a future version.\n","  df[\"comment\"] = df[\"comment\"].astype(str).str.replace('[^\\w\\s]','')\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}]},{"cell_type":"code","source":["# Split the preprocessed comments into training and testing sets\n","split_ratio = 0.8\n","train_size = int(len(preprocessed_comments) * split_ratio)\n","train_comments = preprocessed_comments[:train_size]\n","test_comments = preprocessed_comments[train_size:]\n","\n","# Convert the preprocessed comments into a numerical format\n","vectorizer = TfidfVectorizer()\n","train_vectors = vectorizer.fit_transform(train_comments)\n","test_vectors = vectorizer.transform(test_comments)\n"],"metadata":{"id":"54nrpNKwFUY6","executionInfo":{"status":"ok","timestamp":1677936563608,"user_tz":-330,"elapsed":8,"user":{"displayName":"NIRAJ MATERE","userId":"18266484789499151383"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Train the Word2Vec model on the preprocessed comments\n","model = gensim.models.Word2Vec(preprocessed_comments, size=1000, window=5, min_count=5, workers=4)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X83-ugOuFXMG","executionInfo":{"status":"ok","timestamp":1677936572675,"user_tz":-330,"elapsed":9074,"user":{"displayName":"NIRAJ MATERE","userId":"18266484789499151383"}},"outputId":"982bdf53-2734-42b4-b947-fb4002a39fb1"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n"]}]},{"cell_type":"code","source":["sentences = [['southee', 'bowls', 'a', 'perfect', 'delivery'], ['batsman', 'hits', 'southee', 'for', 'a', 'six']]\n","model = gensim.models.Word2Vec(sentences, min_count=1, size=100)\n","sentences = [['gayle', 'bowls', 'a', 'underway', 'delivery'], ['batsman', 'hits', 'southee', 'for', 'a', 'four']]\n","model = gensim.models.Word2Vec(sentences, min_count=1, size=100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N680-yl6JYWU","executionInfo":{"status":"ok","timestamp":1677936572676,"user_tz":-330,"elapsed":27,"user":{"displayName":"NIRAJ MATERE","userId":"18266484789499151383"}},"outputId":"892a5072-db73-427f-adce-23b278e3be45"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n","WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"]}]},{"cell_type":"markdown","source":["Adding player names to model vocabulary."],"metadata":{"id":"aBxRxxk6-lZM"}},{"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"id":"kGS5NF0IfFlD","executionInfo":{"status":"ok","timestamp":1677936592527,"user_tz":-330,"elapsed":19874,"user":{"displayName":"NIRAJ MATERE","userId":"18266484789499151383"}},"outputId":"c6b65875-1d36-44e1-d7ca-c9e02a10bc43"},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-84742779-9773-481b-9a1a-8d36b2cb21d4\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-84742779-9773-481b-9a1a-8d36b2cb21d4\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving names.csv to names (1).csv\n"]}]},{"cell_type":"markdown","source":["Adding player names to model vocabulary."],"metadata":{"id":"YGzUl6EU193w"}},{"cell_type":"code","source":["import csv"],"metadata":{"id":"mdSHR5v3fHM9","executionInfo":{"status":"ok","timestamp":1677936592528,"user_tz":-330,"elapsed":20,"user":{"displayName":"NIRAJ MATERE","userId":"18266484789499151383"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["player_names = []\n","# Read player names from csv file\n","with open('names.csv', 'r') as csvfile:\n","    csvreader = csv.reader(csvfile)\n","    for row in csvreader:\n","        player_names.append(row[0])"],"metadata":{"id":"nffNu1Tle0zH","executionInfo":{"status":"ok","timestamp":1677936592529,"user_tz":-330,"elapsed":18,"user":{"displayName":"NIRAJ MATERE","userId":"18266484789499151383"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Add player names to vocabulary\n","model.build_vocab([player_names], update=True)"],"metadata":{"id":"MC5te8vXe6-x","executionInfo":{"status":"ok","timestamp":1677936593239,"user_tz":-330,"elapsed":728,"user":{"displayName":"NIRAJ MATERE","userId":"18266484789499151383"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["Training the model on text8 corpus."],"metadata":{"id":"CLkK4YyZ15ue"}},{"cell_type":"code","source":["import gensim.downloader as api"],"metadata":{"id":"gB2SAa_xx9bK","executionInfo":{"status":"ok","timestamp":1677936593239,"user_tz":-330,"elapsed":4,"user":{"displayName":"NIRAJ MATERE","userId":"18266484789499151383"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Download the text8 corpus\n","corpus = api.load('text8')"],"metadata":{"id":"soeW3GS2xvSP","executionInfo":{"status":"ok","timestamp":1677936593240,"user_tz":-330,"elapsed":4,"user":{"displayName":"NIRAJ MATERE","userId":"18266484789499151383"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Add the corpus to the model's vocabulary\n","model.build_vocab(corpus, update=True)"],"metadata":{"id":"uwgwV2R0xxns","executionInfo":{"status":"ok","timestamp":1677936662469,"user_tz":-330,"elapsed":69233,"user":{"displayName":"NIRAJ MATERE","userId":"18266484789499151383"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# Train the model on the corpus\n","model.train(corpus, total_examples=model.corpus_count, epochs=model.epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yqJV60CPxySw","executionInfo":{"status":"ok","timestamp":1677936820561,"user_tz":-330,"elapsed":158108,"user":{"displayName":"NIRAJ MATERE","userId":"18266484789499151383"}},"outputId":"194ed7d2-36a6-4ce4-bb9e-82d32b8af040"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(64096283, 85026035)"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["Training the model on wikipedia corpus."],"metadata":{"id":"XAVxfA1e1yNT"}},{"cell_type":"code","source":["!pip install wikipedia\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dledooSx2bbM","executionInfo":{"status":"ok","timestamp":1677937206619,"user_tz":-330,"elapsed":6101,"user":{"displayName":"NIRAJ MATERE","userId":"18266484789499151383"}},"outputId":"30a49cb8-12ff-405d-b75d-1ae72830dfa6"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wikipedia\n","  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from wikipedia) (4.6.3)\n","Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from wikipedia) (2.25.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.14)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.10)\n","Building wheels for collected packages: wikipedia\n","  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11695 sha256=8a1d88f71aa161346c6a5a04d24f2bbe491340292957cc78a5b7bf165caf3c83\n","  Stored in directory: /root/.cache/pip/wheels/07/93/05/72c05349177dca2e0ba31a33ba4f7907606f7ddef303517c6a\n","Successfully built wikipedia\n","Installing collected packages: wikipedia\n","Successfully installed wikipedia-1.4.0\n"]}]},{"cell_type":"code","source":["import logging\n","import wikipedia\n","from gensim.corpora import WikiCorpus\n","from gensim.utils import simple_preprocess\n","import requests\n","import bz2"],"metadata":{"id":"uYEsKnMh1xQg","executionInfo":{"status":"ok","timestamp":1677937556927,"user_tz":-330,"elapsed":407,"user":{"displayName":"NIRAJ MATERE","userId":"18266484789499151383"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["# Set up logging\n","logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n"],"metadata":{"id":"ooMVUYIu2ZU9","executionInfo":{"status":"ok","timestamp":1677937579390,"user_tz":-330,"elapsed":3,"user":{"displayName":"NIRAJ MATERE","userId":"18266484789499151383"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["this code downloads a large file (over 16 GB in size) from the internet, so it may take several hours to complete depending on the above-mentioned factors. It is important to note that downloading large files can consume a significant amount of bandwidth and can affect the internet speed for other users on the same network.\n"],"metadata":{"id":"2mj_Lpe4H-Ig"}},{"cell_type":"code","source":["# Download a Wikipedia dump file in XML format\n","wiki_dump_file = 'enwiki-latest-pages-articles.xml.bz2'\n","url = 'https://dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2'\n","r = requests.get(url, stream=True)\n","with open(wiki_dump_file, 'wb') as f:\n","    for chunk in r.iter_content(chunk_size=1024):\n","        if chunk:\n","            f.write(chunk)"],"metadata":{"id":"SQDUD1du2hG8","executionInfo":{"status":"ok","timestamp":1677942183367,"user_tz":-330,"elapsed":4599670,"user":{"displayName":"NIRAJ MATERE","userId":"18266484789499151383"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["# Use WikiCorpus to extract text from the Wikipedia dump\n","wiki_corpus = WikiCorpus(wiki_dump_file, dictionary={})\n","sentences = list(wiki_corpus.get_texts())"],"metadata":{"id":"qsNkRbJ_3Trs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Preprocess the text data\n","preprocessed_sentences = [simple_preprocess(sentence) for sentence in sentences]\n"],"metadata":{"id":"L2YuEWwz3Xzp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train a Word2Vec model using the preprocessed text data\n","model = gensim.models.Word2Vec(preprocessed_sentences, min_count=5, workers=4)"],"metadata":{"id":"XlYVuDvu3YpN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Function to generate summary."],"metadata":{"id":"Oqi4jAvi2yJY"}},{"cell_type":"code","source":["# Define a function to generate summaries for a given match\n","def generate_summary(match_id):\n","    # Get all the preprocessed comments for the given match\n","    comments = df.loc[df[\"Match_id\"] == match_id, \"comment\"].tolist()\n","    \n","    # Convert the preprocessed comments to vectors using the Word2Vec model\n","    comment_vectors = [model.wv[comment.split()] for comment in comments]\n","    \n","    # Summarize the comments using the TextRank algorithm\n","    summary = summarize(\" \".join(comments), ratio=0.2)\n","    \n","    return summary"],"metadata":{"id":"QZHuClJnFY4u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Generate summary for each match."],"metadata":{"id":"NLE2a03t-67n"}},{"cell_type":"code","source":["# Generate summaries for all matches in the test set\n","predicted_summaries = []\n","for Match_id in df.loc[train_size:, \"Match_id\"].unique():\n","    summary = generate_summary(Match_id)\n","    predicted_summaries.append(summary)\n","\n","print(predicted_summaries)\n"],"metadata":{"id":"lJc8bAKvFbbw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Performance measurement."],"metadata":{"id":"VziHuKiL_BwP"}},{"cell_type":"code","source":["# Evaluate the model using mean squared error\n","actual_summaries = df.loc[train_size:, \"comment\"].tolist()\n","mse = mean_squared_error(actual_summaries, predicted_summaries)\n","rmse = sqrt(mse)\n","print(\"Root Mean Squared Error:\", rmse)"],"metadata":{"id":"7f-10nj6Ff8f","executionInfo":{"status":"aborted","timestamp":1677936821584,"user_tz":-330,"elapsed":11,"user":{"displayName":"NIRAJ MATERE","userId":"18266484789499151383"}}},"execution_count":null,"outputs":[]}]}